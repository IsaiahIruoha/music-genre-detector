{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b2fae50",
   "metadata": {},
   "source": [
    "# Supervised Learning Music Genre Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e886f4ed",
   "metadata": {},
   "source": [
    "## Import Statements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b590e7",
   "metadata": {},
   "source": [
    "Start by importing necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "22138a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import pandas as pd\n",
    "from pydub import AudioSegment\n",
    "import tempfile\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a0285f",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e9fb7d",
   "metadata": {},
   "source": [
    "Convert to MP3 function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "1e3d8b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_mp3_to_wav(mp3_file):\n",
    "    try:\n",
    "        sound = AudioSegment.from_mp3(mp3_file)\n",
    "        wav_file = tempfile.mktemp(suffix='.wav')\n",
    "        sound.export(wav_file, format=\"wav\")\n",
    "        return wav_file\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting {mp3_file} to WAV: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e514b2",
   "metadata": {},
   "source": [
    "Feature extraction from a segment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "5aa55f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract features from an audio segment\n",
    "def extract_features_from_segment(y, sr, start_time, end_time):\n",
    "    segment = y[start_time:end_time]\n",
    "\n",
    "    # Compute chroma feature from the waveform and sample rate\n",
    "    chroma_stft = librosa.feature.chroma_stft(y=segment, sr=sr)\n",
    "    # Compute Root Mean Square (RMS) energy for each frame\n",
    "    rms = librosa.feature.rms(y=segment)\n",
    "    # Compute spectral centroid, which indicates where the center of mass for a sound is located\n",
    "    spectral_centroid = librosa.feature.spectral_centroid(y=segment, sr=sr)\n",
    "    # Compute spectral bandwidth, which is a measure of the width of the band of frequencies\n",
    "    spectral_bandwidth = librosa.feature.spectral_bandwidth(y=segment, sr=sr)\n",
    "    # Compute spectral rolloff point, which is the frequency below which a specified percentage of the total spectral energy lies\n",
    "    rolloff = librosa.feature.spectral_rolloff(y=segment, sr=sr)\n",
    "    # Compute zero crossing rate, which is the rate at which the signal changes sign\n",
    "    zero_crossing_rate = librosa.feature.zero_crossing_rate(y=segment)\n",
    "    # Compute harmony and perceptr (percussive) components of the audio\n",
    "    harmony, perceptr = librosa.effects.hpss(segment)\n",
    "    # Compute tempo (beats per minute)\n",
    "    tempo, _ = librosa.beat.beat_track(y=segment, sr=sr)\n",
    "    # Compute Mel-frequency cepstral coefficients (MFCCs)\n",
    "    mfcc = librosa.feature.mfcc(y=segment, sr=sr, n_mfcc=20)\n",
    "\n",
    "    # Aggregate the features into a dictionary\n",
    "    features = {\n",
    "        'chroma_stft_mean': chroma_stft.mean() if chroma_stft.size else 0,\n",
    "        'chroma_stft_var': chroma_stft.var() if chroma_stft.size else 0,\n",
    "        'rms_mean': rms.mean() if rms.size else 0,\n",
    "        'rms_var': rms.var() if rms.size else 0,\n",
    "        'spectral_centroid_mean': spectral_centroid.mean() if spectral_centroid.size else 0,\n",
    "        'spectral_centroid_var': spectral_centroid.var() if spectral_centroid.size else 0,\n",
    "        'spectral_bandwidth_mean': spectral_bandwidth.mean() if spectral_bandwidth.size else 0,\n",
    "        'spectral_bandwidth_var': spectral_bandwidth.var() if spectral_bandwidth.size else 0,\n",
    "        'rolloff_mean': rolloff.mean() if rolloff.size else 0,\n",
    "        'rolloff_var': rolloff.var() if rolloff.size else 0,\n",
    "        'zero_crossing_rate_mean': zero_crossing_rate.mean() if zero_crossing_rate.size else 0,\n",
    "        'zero_crossing_rate_var': zero_crossing_rate.var() if zero_crossing_rate.size else 0,\n",
    "        'harmony_mean': harmony.mean() if harmony.size else 0,\n",
    "        'harmony_var': harmony.var() if harmony.size else 0,\n",
    "        'perceptr_mean': perceptr.mean() if perceptr.size else 0,\n",
    "        'perceptr_var': perceptr.var() if perceptr.size else 0,\n",
    "        'tempo': tempo,\n",
    "    }\n",
    "\n",
    "    for i in range(1, 21):\n",
    "        features[f'mfcc{i}_mean'] = mfcc[i-1].mean() if mfcc.shape[0] >= i else 0\n",
    "        features[f'mfcc{i}_var'] = mfcc[i-1].var() if mfcc.shape[0] >= i else 0\n",
    "\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa5f717",
   "metadata": {},
   "source": [
    "Segment data and call feature extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "75e1c6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract features from an audio file\n",
    "def extract_features(audio_file, segment_duration=3):\n",
    "    try:\n",
    "        # Load the audio file\n",
    "        y, sr = librosa.load(audio_file, sr=None)\n",
    "        total_duration = len(y) / sr\n",
    "        segment_length = int(sr * segment_duration)\n",
    "\n",
    "        features_list = []\n",
    "\n",
    "        for start in range(0, len(y), segment_length):\n",
    "            end = start + segment_length\n",
    "            if end <= len(y):\n",
    "                segment_features = extract_features_from_segment(y, sr, start, end)\n",
    "                segment_features['filename'] = os.path.basename(audio_file)\n",
    "                segment_features['start'] = start / sr\n",
    "                segment_features['end'] = end / sr\n",
    "                features_list.append(segment_features)\n",
    "\n",
    "        return features_list\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting features from {audio_file}: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3851f10",
   "metadata": {},
   "source": [
    "## Define Data Paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96da33c7",
   "metadata": {},
   "source": [
    "Specify the paths to the CSV files containing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "0784aec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of genres\n",
    "genres = [\"blues\", \"classical\", \"country\", \"disco\", \"hiphop\", \"jazz\", \"metal\", \"pop\", \"reggae\", \"rock\"]\n",
    "\n",
    "# Base folder containing genre subfolders\n",
    "base_folder_path = '/Users/lchilly/Desktop/Astra/genres_original'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953974b0",
   "metadata": {},
   "source": [
    "## Process Input Audio Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0d4edc",
   "metadata": {},
   "source": [
    "Process input files and label the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "ec7af356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function to process all audio files in a folder\n",
    "def process_audio_folder(folder_path, genre_label):\n",
    "    results = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.wav') or filename.endswith('.mp3'):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            if filename.endswith('.mp3'):\n",
    "                try:\n",
    "                    file_path = convert_mp3_to_wav(file_path)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error converting {file_path} to WAV: {e}\")\n",
    "                    continue\n",
    "            features_list = extract_features(file_path)\n",
    "            for features in features_list:\n",
    "                features['genre'] = genre_label\n",
    "                results.append(features)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a872c4cd",
   "metadata": {},
   "source": [
    "## Create Singular CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9fc8b6",
   "metadata": {},
   "source": [
    "Aggregate results of the feature extraction into a singular CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "c7412610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing genre: blues\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[156], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing genre: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgenre\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m folder_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(base_folder_path, genre)\n\u001b[0;32m----> 8\u001b[0m genre_results \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_audio_folder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfolder_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenre\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m all_results\u001b[38;5;241m.\u001b[39mextend(genre_results)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompleted processing genre: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgenre\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[155], line 13\u001b[0m, in \u001b[0;36mprocess_audio_folder\u001b[0;34m(folder_path, genre_label)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError converting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to WAV: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m features_list \u001b[38;5;241m=\u001b[39m \u001b[43mextract_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m features \u001b[38;5;129;01min\u001b[39;00m features_list:\n\u001b[1;32m     15\u001b[0m     features[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenre\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m genre_label\n",
      "Cell \u001b[0;32mIn[153], line 14\u001b[0m, in \u001b[0;36mextract_features\u001b[0;34m(audio_file, segment_duration)\u001b[0m\n\u001b[1;32m     12\u001b[0m end \u001b[38;5;241m=\u001b[39m start \u001b[38;5;241m+\u001b[39m segment_length\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(y):\n\u001b[0;32m---> 14\u001b[0m     segment_features \u001b[38;5;241m=\u001b[39m \u001b[43mextract_features_from_segment\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     segment_features[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfilename\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(audio_file)\n\u001b[1;32m     16\u001b[0m     segment_features[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m start \u001b[38;5;241m/\u001b[39m sr\n",
      "Cell \u001b[0;32mIn[152], line 18\u001b[0m, in \u001b[0;36mextract_features_from_segment\u001b[0;34m(y, sr, start_time, end_time)\u001b[0m\n\u001b[1;32m     16\u001b[0m zero_crossing_rate \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mfeature\u001b[38;5;241m.\u001b[39mzero_crossing_rate(y\u001b[38;5;241m=\u001b[39msegment)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Compute harmony and perceptr (percussive) components of the audio\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m harmony, perceptr \u001b[38;5;241m=\u001b[39m \u001b[43mlibrosa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meffects\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhpss\u001b[49m\u001b[43m(\u001b[49m\u001b[43msegment\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Compute tempo (beats per minute)\u001b[39;00m\n\u001b[1;32m     20\u001b[0m tempo, _ \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mbeat\u001b[38;5;241m.\u001b[39mbeat_track(y\u001b[38;5;241m=\u001b[39msegment, sr\u001b[38;5;241m=\u001b[39msr)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/librosa/effects.py:143\u001b[0m, in \u001b[0;36mhpss\u001b[0;34m(y, kernel_size, power, mask, margin, n_fft, hop_length, win_length, window, center, pad_mode)\u001b[0m\n\u001b[1;32m    133\u001b[0m stft \u001b[38;5;241m=\u001b[39m core\u001b[38;5;241m.\u001b[39mstft(\n\u001b[1;32m    134\u001b[0m     y,\n\u001b[1;32m    135\u001b[0m     n_fft\u001b[38;5;241m=\u001b[39mn_fft,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    139\u001b[0m     pad_mode\u001b[38;5;241m=\u001b[39mpad_mode,\n\u001b[1;32m    140\u001b[0m )\n\u001b[1;32m    142\u001b[0m \u001b[38;5;66;03m# Decompose into harmonic and percussives\u001b[39;00m\n\u001b[0;32m--> 143\u001b[0m stft_harm, stft_perc \u001b[38;5;241m=\u001b[39m \u001b[43mdecompose\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhpss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpower\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpower\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmargin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmargin\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;66;03m# Invert the STFTs.  Adjust length to match the input.\u001b[39;00m\n\u001b[1;32m    148\u001b[0m y_harm \u001b[38;5;241m=\u001b[39m core\u001b[38;5;241m.\u001b[39mistft(\n\u001b[1;32m    149\u001b[0m     stft_harm,\n\u001b[1;32m    150\u001b[0m     dtype\u001b[38;5;241m=\u001b[39my\u001b[38;5;241m.\u001b[39mdtype,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    155\u001b[0m     length\u001b[38;5;241m=\u001b[39my\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m    156\u001b[0m )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/librosa/decompose.py:390\u001b[0m, in \u001b[0;36mhpss\u001b[0;34m(S, kernel_size, power, mask, margin)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;66;03m# Compute median filters. Pre-allocation here preserves memory layout.\u001b[39;00m\n\u001b[1;32m    389\u001b[0m harm \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty_like(S)\n\u001b[0;32m--> 390\u001b[0m harm[:] \u001b[38;5;241m=\u001b[39m \u001b[43mmedian_filter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mharm_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreflect\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    392\u001b[0m perc \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty_like(S)\n\u001b[1;32m    393\u001b[0m perc[:] \u001b[38;5;241m=\u001b[39m median_filter(S, size\u001b[38;5;241m=\u001b[39mperc_shape, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreflect\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/scipy/ndimage/_filters.py:1594\u001b[0m, in \u001b[0;36mmedian_filter\u001b[0;34m(input, size, footprint, output, mode, cval, origin, axes)\u001b[0m\n\u001b[1;32m   1547\u001b[0m \u001b[38;5;129m@_ni_docstrings\u001b[39m\u001b[38;5;241m.\u001b[39mdocfiller\n\u001b[1;32m   1548\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmedian_filter\u001b[39m(\u001b[38;5;28minput\u001b[39m, size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, footprint\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1549\u001b[0m                   mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreflect\u001b[39m\u001b[38;5;124m\"\u001b[39m, cval\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m, origin\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m*\u001b[39m, axes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1550\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1551\u001b[0m \u001b[38;5;124;03m    Calculate a multidimensional median filter.\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1592\u001b[0m \u001b[38;5;124;03m    >>> plt.show()\u001b[39;00m\n\u001b[1;32m   1593\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1594\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_rank_filter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfootprint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1595\u001b[0m \u001b[43m                        \u001b[49m\u001b[43morigin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmedian\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/scipy/ndimage/_filters.py:1495\u001b[0m, in \u001b[0;36m_rank_filter\u001b[0;34m(input, rank, size, footprint, output, mode, cval, origin, operation, axes)\u001b[0m\n\u001b[1;32m   1491\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1492\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA sequence of modes is not supported by non-separable rank \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1493\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilters\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1494\u001b[0m mode \u001b[38;5;241m=\u001b[39m _ni_support\u001b[38;5;241m.\u001b[39m_extend_mode_to_code(mode)\n\u001b[0;32m-> 1495\u001b[0m \u001b[43m_nd_image\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrank_filter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrank\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfootprint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1496\u001b[0m \u001b[43m                      \u001b[49m\u001b[43morigins\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m temp_needed:\n\u001b[1;32m   1498\u001b[0m     temp[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m] \u001b[38;5;241m=\u001b[39m output\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Collect results from all genres\n",
    "all_results = []\n",
    "\n",
    "# Process each genre\n",
    "for genre in genres:\n",
    "    print(f\"Processing genre: {genre}\")\n",
    "    folder_path = os.path.join(base_folder_path, genre)\n",
    "    genre_results = process_audio_folder(folder_path, genre)\n",
    "    all_results.extend(genre_results)\n",
    "    print(f\"Completed processing genre: {genre}\")\n",
    "\n",
    "# Write all results to a single CSV file\n",
    "print(\"Writing results to CSV file...\")\n",
    "df = pd.DataFrame(all_results)\n",
    "csv_file_path = '/Users/lchilly/Desktop/Astra/music-genre-classification/all_genres_audio_features.csv'\n",
    "df.to_csv(csv_file_path, index=False)\n",
    "print(\"CSV file generation completed.\")\n",
    "\n",
    "# I (simon) mainly added this for testing just so I could see when everything is done\n",
    "print(\"Feature extraction and CSV generation completed for all genres.\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f0d23c",
   "metadata": {},
   "source": [
    "## Examine Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f555dd",
   "metadata": {},
   "source": [
    "Gain insights into data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "05cf96d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chroma_stft_mean</th>\n",
       "      <th>chroma_stft_var</th>\n",
       "      <th>rms_mean</th>\n",
       "      <th>rms_var</th>\n",
       "      <th>spectral_centroid_mean</th>\n",
       "      <th>spectral_centroid_var</th>\n",
       "      <th>spectral_bandwidth_mean</th>\n",
       "      <th>spectral_bandwidth_var</th>\n",
       "      <th>rolloff_mean</th>\n",
       "      <th>rolloff_var</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc17_mean</th>\n",
       "      <th>mfcc17_var</th>\n",
       "      <th>mfcc18_mean</th>\n",
       "      <th>mfcc18_var</th>\n",
       "      <th>mfcc19_mean</th>\n",
       "      <th>mfcc19_var</th>\n",
       "      <th>mfcc20_mean</th>\n",
       "      <th>mfcc20_var</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9981.000000</td>\n",
       "      <td>9981.000000</td>\n",
       "      <td>9981.000000</td>\n",
       "      <td>9.981000e+03</td>\n",
       "      <td>9981.000000</td>\n",
       "      <td>9.981000e+03</td>\n",
       "      <td>9981.000000</td>\n",
       "      <td>9.981000e+03</td>\n",
       "      <td>9981.000000</td>\n",
       "      <td>9.981000e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>9981.000000</td>\n",
       "      <td>9981.000000</td>\n",
       "      <td>9981.000000</td>\n",
       "      <td>9981.000000</td>\n",
       "      <td>9981.000000</td>\n",
       "      <td>9981.000000</td>\n",
       "      <td>9981.000000</td>\n",
       "      <td>9981.000000</td>\n",
       "      <td>9981.000000</td>\n",
       "      <td>9981.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.379964</td>\n",
       "      <td>0.084882</td>\n",
       "      <td>0.130039</td>\n",
       "      <td>2.672433e-03</td>\n",
       "      <td>2201.910957</td>\n",
       "      <td>4.159255e+05</td>\n",
       "      <td>2244.562460</td>\n",
       "      <td>1.183121e+05</td>\n",
       "      <td>4571.568401</td>\n",
       "      <td>1.623468e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.193187</td>\n",
       "      <td>51.838395</td>\n",
       "      <td>0.724376</td>\n",
       "      <td>52.343694</td>\n",
       "      <td>-2.497094</td>\n",
       "      <td>54.811697</td>\n",
       "      <td>-0.929246</td>\n",
       "      <td>57.142098</td>\n",
       "      <td>13.487827</td>\n",
       "      <td>16.487827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.090624</td>\n",
       "      <td>0.009675</td>\n",
       "      <td>0.068168</td>\n",
       "      <td>3.561532e-03</td>\n",
       "      <td>750.540439</td>\n",
       "      <td>4.339675e+05</td>\n",
       "      <td>541.420376</td>\n",
       "      <td>1.002501e+05</td>\n",
       "      <td>1639.481644</td>\n",
       "      <td>1.482634e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>5.668784</td>\n",
       "      <td>36.301829</td>\n",
       "      <td>5.175797</td>\n",
       "      <td>38.067790</td>\n",
       "      <td>5.107192</td>\n",
       "      <td>41.505894</td>\n",
       "      <td>5.247202</td>\n",
       "      <td>46.342797</td>\n",
       "      <td>8.611614</td>\n",
       "      <td>8.611614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.108073</td>\n",
       "      <td>0.015217</td>\n",
       "      <td>0.000947</td>\n",
       "      <td>4.055916e-08</td>\n",
       "      <td>479.905803</td>\n",
       "      <td>2.161498e+03</td>\n",
       "      <td>499.577101</td>\n",
       "      <td>1.295350e+03</td>\n",
       "      <td>673.906438</td>\n",
       "      <td>1.130834e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>-27.932220</td>\n",
       "      <td>1.531856</td>\n",
       "      <td>-20.749746</td>\n",
       "      <td>3.445751</td>\n",
       "      <td>-27.359076</td>\n",
       "      <td>3.147764</td>\n",
       "      <td>-35.614895</td>\n",
       "      <td>0.253587</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.316037</td>\n",
       "      <td>0.079820</td>\n",
       "      <td>0.083223</td>\n",
       "      <td>6.285820e-04</td>\n",
       "      <td>1634.097151</td>\n",
       "      <td>1.228336e+05</td>\n",
       "      <td>1890.204723</td>\n",
       "      <td>4.941410e+04</td>\n",
       "      <td>3389.905912</td>\n",
       "      <td>5.562385e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.948162</td>\n",
       "      <td>29.821222</td>\n",
       "      <td>-2.524088</td>\n",
       "      <td>29.405123</td>\n",
       "      <td>-5.734853</td>\n",
       "      <td>30.384863</td>\n",
       "      <td>-4.012720</td>\n",
       "      <td>29.925747</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.385163</td>\n",
       "      <td>0.085137</td>\n",
       "      <td>0.120488</td>\n",
       "      <td>1.500287e-03</td>\n",
       "      <td>2211.777107</td>\n",
       "      <td>2.643931e+05</td>\n",
       "      <td>2233.071917</td>\n",
       "      <td>9.037122e+04</td>\n",
       "      <td>4634.773513</td>\n",
       "      <td>1.155826e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.444725</td>\n",
       "      <td>42.235080</td>\n",
       "      <td>0.730935</td>\n",
       "      <td>41.686157</td>\n",
       "      <td>-2.700388</td>\n",
       "      <td>43.264107</td>\n",
       "      <td>-1.045194</td>\n",
       "      <td>44.173588</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.442906</td>\n",
       "      <td>0.091154</td>\n",
       "      <td>0.175334</td>\n",
       "      <td>3.113760e-03</td>\n",
       "      <td>2713.457812</td>\n",
       "      <td>5.612200e+05</td>\n",
       "      <td>2590.295338</td>\n",
       "      <td>1.578929e+05</td>\n",
       "      <td>5597.307692</td>\n",
       "      <td>2.251497e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.731065</td>\n",
       "      <td>61.467625</td>\n",
       "      <td>3.871771</td>\n",
       "      <td>61.854340</td>\n",
       "      <td>0.521315</td>\n",
       "      <td>65.165130</td>\n",
       "      <td>2.192562</td>\n",
       "      <td>68.000710</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.751176</td>\n",
       "      <td>0.120717</td>\n",
       "      <td>0.440458</td>\n",
       "      <td>3.237973e-02</td>\n",
       "      <td>5432.278842</td>\n",
       "      <td>4.801847e+06</td>\n",
       "      <td>3708.279664</td>\n",
       "      <td>1.237131e+06</td>\n",
       "      <td>9486.121357</td>\n",
       "      <td>1.293661e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>33.869503</td>\n",
       "      <td>523.140560</td>\n",
       "      <td>36.923035</td>\n",
       "      <td>628.774400</td>\n",
       "      <td>31.367567</td>\n",
       "      <td>1147.502400</td>\n",
       "      <td>34.130856</td>\n",
       "      <td>914.816200</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       chroma_stft_mean  chroma_stft_var     rms_mean       rms_var  \\\n",
       "count       9981.000000      9981.000000  9981.000000  9.981000e+03   \n",
       "mean           0.379964         0.084882     0.130039  2.672433e-03   \n",
       "std            0.090624         0.009675     0.068168  3.561532e-03   \n",
       "min            0.108073         0.015217     0.000947  4.055916e-08   \n",
       "25%            0.316037         0.079820     0.083223  6.285820e-04   \n",
       "50%            0.385163         0.085137     0.120488  1.500287e-03   \n",
       "75%            0.442906         0.091154     0.175334  3.113760e-03   \n",
       "max            0.751176         0.120717     0.440458  3.237973e-02   \n",
       "\n",
       "       spectral_centroid_mean  spectral_centroid_var  spectral_bandwidth_mean  \\\n",
       "count             9981.000000           9.981000e+03              9981.000000   \n",
       "mean              2201.910957           4.159255e+05              2244.562460   \n",
       "std                750.540439           4.339675e+05               541.420376   \n",
       "min                479.905803           2.161498e+03               499.577101   \n",
       "25%               1634.097151           1.228336e+05              1890.204723   \n",
       "50%               2211.777107           2.643931e+05              2233.071917   \n",
       "75%               2713.457812           5.612200e+05              2590.295338   \n",
       "max               5432.278842           4.801847e+06              3708.279664   \n",
       "\n",
       "       spectral_bandwidth_var  rolloff_mean   rolloff_var  ...  mfcc17_mean  \\\n",
       "count            9.981000e+03   9981.000000  9.981000e+03  ...  9981.000000   \n",
       "mean             1.183121e+05   4571.568401  1.623468e+06  ...    -4.193187   \n",
       "std              1.002501e+05   1639.481644  1.482634e+06  ...     5.668784   \n",
       "min              1.295350e+03    673.906438  1.130834e+03  ...   -27.932220   \n",
       "25%              4.941410e+04   3389.905912  5.562385e+05  ...    -7.948162   \n",
       "50%              9.037122e+04   4634.773513  1.155826e+06  ...    -4.444725   \n",
       "75%              1.578929e+05   5597.307692  2.251497e+06  ...    -0.731065   \n",
       "max              1.237131e+06   9486.121357  1.293661e+07  ...    33.869503   \n",
       "\n",
       "        mfcc17_var  mfcc18_mean   mfcc18_var  mfcc19_mean   mfcc19_var  \\\n",
       "count  9981.000000  9981.000000  9981.000000  9981.000000  9981.000000   \n",
       "mean     51.838395     0.724376    52.343694    -2.497094    54.811697   \n",
       "std      36.301829     5.175797    38.067790     5.107192    41.505894   \n",
       "min       1.531856   -20.749746     3.445751   -27.359076     3.147764   \n",
       "25%      29.821222    -2.524088    29.405123    -5.734853    30.384863   \n",
       "50%      42.235080     0.730935    41.686157    -2.700388    43.264107   \n",
       "75%      61.467625     3.871771    61.854340     0.521315    65.165130   \n",
       "max     523.140560    36.923035   628.774400    31.367567  1147.502400   \n",
       "\n",
       "       mfcc20_mean   mfcc20_var        start          end  \n",
       "count  9981.000000  9981.000000  9981.000000  9981.000000  \n",
       "mean     -0.929246    57.142098    13.487827    16.487827  \n",
       "std       5.247202    46.342797     8.611614     8.611614  \n",
       "min     -35.614895     0.253587     0.000000     3.000000  \n",
       "25%      -4.012720    29.925747     6.000000     9.000000  \n",
       "50%      -1.045194    44.173588    12.000000    15.000000  \n",
       "75%       2.192562    68.000710    21.000000    24.000000  \n",
       "max      34.130856   914.816200    27.000000    30.000000  \n",
       "\n",
       "[8 rows x 58 columns]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get summary statistics\n",
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58539520",
   "metadata": {},
   "source": [
    "Check for duplicates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "703ac5dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates or null values found in data\n"
     ]
    }
   ],
   "source": [
    "def check_duplicates_or_nulls(data):\n",
    "    # Check for duplicates\n",
    "    duplicates = data.duplicated().sum() > 0\n",
    "    \n",
    "    # Check for any null values\n",
    "    nulls = data.isnull().sum().sum() > 0\n",
    "    \n",
    "    # Return true if either condition met\n",
    "    return duplicates or nulls\n",
    "\n",
    "# Assuming csv_file_path is a string representing a file path, \n",
    "df = pd.read_csv('all_genres_audio_features.csv')  # Read the CSV file\n",
    "if check_duplicates_or_nulls(data):\n",
    "    print('Duplicates or null values found in data')\n",
    "else:\n",
    "    print('No duplicates or null values found in data')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae3885d",
   "metadata": {},
   "source": [
    "## Shuffle and Split data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc411a3b",
   "metadata": {},
   "source": [
    "Split data into training and testing sets (90/10)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "856874ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling and splitting the data into training and testing sets...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Shuffle and split the data into training and testing sets\n",
    "print(\"Shuffling and splitting the data into training and testing sets...\")\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['genre'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ab3cbc",
   "metadata": {},
   "source": [
    "## Begin Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4bc2053",
   "metadata": {},
   "source": [
    "Apply the low pass filter through use of a moving average with a window size of 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "9d39f937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean and convert data\n",
    "def clean_and_convert(df):\n",
    "    feature_columns = df.columns.difference(['filename', 'start', 'end', 'genre'])\n",
    "    for column in feature_columns:\n",
    "        # Convert string representations of numbers or lists to actual numeric values\n",
    "        df[column] = df[column].apply(lambda x: float(x.strip('[]')) if isinstance(x, str) and x.startswith('[') and x.endswith(']') else x)\n",
    "    return df\n",
    "\n",
    "# Apply moving average filter\n",
    "def apply_moving_average_filter(df, window_size=3):\n",
    "    df = clean_and_convert(df)\n",
    "    \n",
    "    feature_columns = df.columns.difference(['filename', 'start', 'end', 'genre'])\n",
    "    df[feature_columns] = df[feature_columns].rolling(window=window_size, min_periods=1).mean()\n",
    "    return df\n",
    "\n",
    "train_df = apply_moving_average_filter(train_df)\n",
    "test_df = apply_moving_average_filter(test_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e58b73",
   "metadata": {},
   "source": [
    "## Z Score normalization is done to the extracted features "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d220a43",
   "metadata": {},
   "source": [
    "Using StandardScaler to properly normalize the individual features for the train and test set, converting back to data frames upon completion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "07169375",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Apply z-score normalization\n",
    "def apply_zscore_normalization(train_df, test_df):\n",
    "    feature_columns = train_df.columns.difference(['filename', 'start', 'end', 'genre'])\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    # Fit the scaler on the training data\n",
    "    train_df[feature_columns] = scaler.fit_transform(train_df[feature_columns])\n",
    "    \n",
    "    # Transform the testing data\n",
    "    test_df[feature_columns] = scaler.transform(test_df[feature_columns])\n",
    "    \n",
    "    return train_df, test_df\n",
    "\n",
    "train_df, test_df = apply_zscore_normalization(train_df, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06131463",
   "metadata": {},
   "source": [
    "## Separate features and labels for training and testing sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7435bd53",
   "metadata": {},
   "source": [
    "Must make sure that the labels and features themselves remain separate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "0210e444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and labels for training and testing sets\n",
    "X_train = train_df.drop(columns=['filename', 'start', 'end', 'genre'])\n",
    "y_train = train_df['genre']\n",
    "X_test = test_df.drop(columns=['filename', 'start', 'end', 'genre'])\n",
    "y_test = test_df['genre']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1563a6",
   "metadata": {},
   "source": [
    "## Save train and test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17423aa6",
   "metadata": {},
   "source": [
    "save data to separate csv to visualize before feeding into the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "b4d6e8f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and testing CSV files generation completed.\n"
     ]
    }
   ],
   "source": [
    "# Save the training and testing sets to separate CSV files\n",
    "train_features_csv_path = '/Users/lchilly/Desktop/Astra/music-genre-classification/train_audio_features.csv'\n",
    "train_labels_csv_path = '/Users/lchilly/Desktop/Astra/music-genre-classification/train_audio_labels.csv'\n",
    "test_features_csv_path = '/Users/lchilly/Desktop/Astra/music-genre-classification/test_audio_features.csv'\n",
    "test_labels_csv_path = '/Users/lchilly/Desktop/Astra/music-genre-classification/test_audio_labels.csv'\n",
    "\n",
    "X_train.to_csv(train_features_csv_path, index=False)\n",
    "y_train.to_csv(train_labels_csv_path, index=False)\n",
    "X_test.to_csv(test_features_csv_path, index=False)\n",
    "y_test.to_csv(test_labels_csv_path, index=False)\n",
    "print(\"Training and testing CSV files generation completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d089132f",
   "metadata": {},
   "source": [
    "## Run model on Gradient Boosting Machine Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "518cc570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2954431647471207\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       blues       0.28      0.27      0.27       200\n",
      "   classical       0.37      0.52      0.43       200\n",
      "     country       0.23      0.19      0.21       199\n",
      "       disco       0.30      0.27      0.28       200\n",
      "      hiphop       0.25      0.20      0.22       200\n",
      "        jazz       0.29      0.26      0.28       198\n",
      "       metal       0.33      0.37      0.35       200\n",
      "         pop       0.33      0.42      0.37       200\n",
      "      reggae       0.29      0.33      0.31       200\n",
      "        rock       0.20      0.14      0.16       200\n",
      "\n",
      "    accuracy                           0.30      1997\n",
      "   macro avg       0.29      0.30      0.29      1997\n",
      "weighted avg       0.29      0.30      0.29      1997\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load datasets\n",
    "train_features_df = pd.read_csv(train_features_csv_path)\n",
    "train_labels_df = pd.read_csv(train_labels_csv_path)\n",
    "test_features_df = pd.read_csv(test_features_csv_path)\n",
    "test_labels_df = pd.read_csv(test_labels_csv_path)\n",
    "\n",
    "# Extract features and labels\n",
    "X_train = train_features_df\n",
    "y_train = train_labels_df['genre']\n",
    "X_test = test_features_df\n",
    "y_test = test_labels_df['genre']\n",
    "\n",
    "# Encode the target variable\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create the Gradient Boosting model with a manually set learning rate and other parameters\n",
    "gb_model = GradientBoostingClassifier(\n",
    "    n_estimators=100,       # Number of boosting stages\n",
    "    learning_rate=0.05,     # Learning rate shrinks the contribution of each tree\n",
    "    max_depth=4,            # Maximum depth of the individual trees\n",
    "    min_samples_split=10,   # Minimum number of samples required to split an internal node\n",
    "    min_samples_leaf=2,     # Minimum number of samples required to be at a leaf node\n",
    "    subsample=0.9,          # Fraction of samples used for fitting the individual base learners\n",
    "    random_state=42         # Ensures reproducibility\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "gb_model.fit(X_train_scaled, y_train_encoded)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = gb_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test_encoded, y_pred)\n",
    "report = classification_report(y_test_encoded, y_pred, target_names=label_encoder.classes_)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab68640",
   "metadata": {},
   "source": [
    "Model is intialized, trained and test with accuracy scores displayed. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d5147f",
   "metadata": {},
   "source": [
    "## Run Model on Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "5105887e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=  11.4s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=  14.7s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=  10.5s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=  11.4s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=  10.3s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=  10.5s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=  10.9s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=  10.8s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=  10.8s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=  10.9s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=  10.2s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   8.9s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   9.4s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   9.3s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   9.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=  10.7s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   9.9s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=  10.5s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   9.9s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=  10.2s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=  11.4s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=  11.6s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=  11.2s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=  10.9s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=  11.2s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=  11.9s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=  13.1s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=  11.8s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=  11.2s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=  12.7s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   8.4s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   8.2s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   8.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   7.8s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   7.8s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   8.2s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   8.1s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   8.4s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   7.8s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   7.9s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=  10.6s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=  10.6s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=  10.3s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=  10.4s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=  10.4s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=  11.1s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=  10.5s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=  10.5s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=  10.5s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=  10.5s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   9.9s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   9.5s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=  12.6s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=  12.3s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=  13.1s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   8.1s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   7.5s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   7.3s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   6.7s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   7.3s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   9.9s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   9.8s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   9.5s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=  11.6s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   9.8s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=  10.1s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   9.6s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   9.6s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   9.8s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   9.5s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=  12.0s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=  12.4s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=  12.4s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=  11.7s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=  11.8s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   8.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   8.2s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   8.1s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   8.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   8.1s\n",
      "Best Parameters: {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "Accuracy: 0.32398597896845266\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       blues       0.32      0.32      0.32       200\n",
      "   classical       0.35      0.59      0.44       200\n",
      "     country       0.30      0.25      0.27       199\n",
      "       disco       0.30      0.24      0.27       200\n",
      "      hiphop       0.29      0.24      0.26       200\n",
      "        jazz       0.28      0.30      0.29       198\n",
      "       metal       0.34      0.40      0.37       200\n",
      "         pop       0.34      0.40      0.37       200\n",
      "      reggae       0.37      0.35      0.36       200\n",
      "        rock       0.29      0.16      0.21       200\n",
      "\n",
      "    accuracy                           0.32      1997\n",
      "   macro avg       0.32      0.32      0.32      1997\n",
      "weighted avg       0.32      0.32      0.32      1997\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Encode the target variable\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create the SVM model with GridSearchCV to find the best parameters\n",
    "svm_model = SVC()\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': [1, 0.1, 0.01, 0.001],\n",
    "    'kernel': ['rbf']\n",
    "}\n",
    "\n",
    "# Use GridSearchCV to find the best parameters\n",
    "grid = GridSearchCV(svm_model, param_grid, refit=True, verbose=2)\n",
    "grid.fit(X_train_scaled, y_train_encoded)\n",
    "\n",
    "# Get the best model from GridSearchCV\n",
    "best_svm_model = grid.best_estimator_\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = best_svm_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test_encoded, y_pred)\n",
    "report = classification_report(y_test_encoded, y_pred, target_names=label_encoder.classes_)\n",
    "\n",
    "print(f\"Best Parameters: {grid.best_params_}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d106a808",
   "metadata": {},
   "source": [
    "## Accuracy Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fc40aa",
   "metadata": {},
   "source": [
    "Check the model to ensure it is doing well in terms of classifications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fc0dc9",
   "metadata": {},
   "source": [
    "## Cross-validation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3920bd",
   "metadata": {},
   "source": [
    "To ensure that the model is functioning well, cross-validation is done with an average result shown. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
