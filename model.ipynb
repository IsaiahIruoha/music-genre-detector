{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b2fae50",
   "metadata": {},
   "source": [
    "# Supervised Learning Music Genre Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e886f4ed",
   "metadata": {},
   "source": [
    "## Import Statements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b590e7",
   "metadata": {},
   "source": [
    "Start by importing necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "22138a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, learning_curve, validation_curve\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import soundfile as sf\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7e202e",
   "metadata": {},
   "source": [
    "## Import Data from prepared CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2150c4a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9981, 58)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('all_genres_audio_features.csv')\n",
    "data = data.drop(columns= ['filename','start','end']) \n",
    "\n",
    "genres = [\"blues\", \"classical\", \"country\", \"disco\", \"hiphop\", \"jazz\", \"metal\", \"pop\", \"reggae\", \"rock\"]\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58539520",
   "metadata": {},
   "source": [
    "Check for duplicates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "703ac5dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates or null values found in data\n"
     ]
    }
   ],
   "source": [
    "def check_duplicates_or_nulls(data):\n",
    "    duplicates = data.duplicated().sum() > 0\n",
    "    nulls = data.isnull().sum().sum() > 0\n",
    "    return duplicates or nulls\n",
    "\n",
    "if check_duplicates_or_nulls(data):\n",
    "    print('Duplicates or null values found in data')\n",
    "else:\n",
    "    print('No duplicates or null values found in data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a2c169",
   "metadata": {},
   "source": [
    "Deal with strings in features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6012da20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chroma_stft_mean</th>\n",
       "      <th>chroma_stft_var</th>\n",
       "      <th>rms_mean</th>\n",
       "      <th>rms_var</th>\n",
       "      <th>spectral_centroid_mean</th>\n",
       "      <th>spectral_centroid_var</th>\n",
       "      <th>spectral_bandwidth_mean</th>\n",
       "      <th>spectral_bandwidth_var</th>\n",
       "      <th>rolloff_mean</th>\n",
       "      <th>rolloff_var</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc16_var</th>\n",
       "      <th>mfcc17_mean</th>\n",
       "      <th>mfcc17_var</th>\n",
       "      <th>mfcc18_mean</th>\n",
       "      <th>mfcc18_var</th>\n",
       "      <th>mfcc19_mean</th>\n",
       "      <th>mfcc19_var</th>\n",
       "      <th>mfcc20_mean</th>\n",
       "      <th>mfcc20_var</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9981.000000</td>\n",
       "      <td>9981.000000</td>\n",
       "      <td>9981.000000</td>\n",
       "      <td>9.981000e+03</td>\n",
       "      <td>9981.000000</td>\n",
       "      <td>9.981000e+03</td>\n",
       "      <td>9981.000000</td>\n",
       "      <td>9.981000e+03</td>\n",
       "      <td>9981.000000</td>\n",
       "      <td>9.981000e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>9981.000000</td>\n",
       "      <td>9981.000000</td>\n",
       "      <td>9981.000000</td>\n",
       "      <td>9981.000000</td>\n",
       "      <td>9981.000000</td>\n",
       "      <td>9981.000000</td>\n",
       "      <td>9981.000000</td>\n",
       "      <td>9981.000000</td>\n",
       "      <td>9981.000000</td>\n",
       "      <td>9981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.379964</td>\n",
       "      <td>0.084882</td>\n",
       "      <td>0.130039</td>\n",
       "      <td>2.672433e-03</td>\n",
       "      <td>2201.910957</td>\n",
       "      <td>4.159255e+05</td>\n",
       "      <td>2244.562460</td>\n",
       "      <td>1.183121e+05</td>\n",
       "      <td>4571.568401</td>\n",
       "      <td>1.623468e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>49.879672</td>\n",
       "      <td>-4.193187</td>\n",
       "      <td>51.838396</td>\n",
       "      <td>0.724376</td>\n",
       "      <td>52.343694</td>\n",
       "      <td>-2.497094</td>\n",
       "      <td>54.811697</td>\n",
       "      <td>-0.929246</td>\n",
       "      <td>57.142098</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.090624</td>\n",
       "      <td>0.009675</td>\n",
       "      <td>0.068168</td>\n",
       "      <td>3.561532e-03</td>\n",
       "      <td>750.540439</td>\n",
       "      <td>4.339675e+05</td>\n",
       "      <td>541.420376</td>\n",
       "      <td>1.002501e+05</td>\n",
       "      <td>1639.481644</td>\n",
       "      <td>1.482634e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>34.358130</td>\n",
       "      <td>5.668784</td>\n",
       "      <td>36.301829</td>\n",
       "      <td>5.175797</td>\n",
       "      <td>38.067790</td>\n",
       "      <td>5.107192</td>\n",
       "      <td>41.505894</td>\n",
       "      <td>5.247202</td>\n",
       "      <td>46.342797</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.108073</td>\n",
       "      <td>0.015217</td>\n",
       "      <td>0.000947</td>\n",
       "      <td>4.055916e-08</td>\n",
       "      <td>479.905803</td>\n",
       "      <td>2.161498e+03</td>\n",
       "      <td>499.577102</td>\n",
       "      <td>1.295350e+03</td>\n",
       "      <td>673.906438</td>\n",
       "      <td>1.130834e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>1.343237</td>\n",
       "      <td>-27.932222</td>\n",
       "      <td>1.531855</td>\n",
       "      <td>-20.749748</td>\n",
       "      <td>3.445752</td>\n",
       "      <td>-27.359076</td>\n",
       "      <td>3.147765</td>\n",
       "      <td>-35.614895</td>\n",
       "      <td>0.253587</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.316037</td>\n",
       "      <td>0.079820</td>\n",
       "      <td>0.083223</td>\n",
       "      <td>6.285820e-04</td>\n",
       "      <td>1634.097152</td>\n",
       "      <td>1.228336e+05</td>\n",
       "      <td>1890.204723</td>\n",
       "      <td>4.941410e+04</td>\n",
       "      <td>3389.905912</td>\n",
       "      <td>5.562385e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>29.521790</td>\n",
       "      <td>-7.948162</td>\n",
       "      <td>29.821220</td>\n",
       "      <td>-2.524088</td>\n",
       "      <td>29.405123</td>\n",
       "      <td>-5.734853</td>\n",
       "      <td>30.384860</td>\n",
       "      <td>-4.012720</td>\n",
       "      <td>29.925747</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.385163</td>\n",
       "      <td>0.085137</td>\n",
       "      <td>0.120488</td>\n",
       "      <td>1.500287e-03</td>\n",
       "      <td>2211.777107</td>\n",
       "      <td>2.643931e+05</td>\n",
       "      <td>2233.071916</td>\n",
       "      <td>9.037122e+04</td>\n",
       "      <td>4634.773513</td>\n",
       "      <td>1.155826e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>41.505714</td>\n",
       "      <td>-4.444725</td>\n",
       "      <td>42.235080</td>\n",
       "      <td>0.730935</td>\n",
       "      <td>41.686157</td>\n",
       "      <td>-2.700388</td>\n",
       "      <td>43.264107</td>\n",
       "      <td>-1.045194</td>\n",
       "      <td>44.173588</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.442906</td>\n",
       "      <td>0.091154</td>\n",
       "      <td>0.175334</td>\n",
       "      <td>3.113760e-03</td>\n",
       "      <td>2713.457812</td>\n",
       "      <td>5.612200e+05</td>\n",
       "      <td>2590.295338</td>\n",
       "      <td>1.578929e+05</td>\n",
       "      <td>5597.307692</td>\n",
       "      <td>2.251497e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>59.062060</td>\n",
       "      <td>-0.731065</td>\n",
       "      <td>61.467620</td>\n",
       "      <td>3.871771</td>\n",
       "      <td>61.854343</td>\n",
       "      <td>0.521315</td>\n",
       "      <td>65.165120</td>\n",
       "      <td>2.192562</td>\n",
       "      <td>68.000710</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.751176</td>\n",
       "      <td>0.120717</td>\n",
       "      <td>0.440458</td>\n",
       "      <td>3.237973e-02</td>\n",
       "      <td>5432.278843</td>\n",
       "      <td>4.801847e+06</td>\n",
       "      <td>3708.279663</td>\n",
       "      <td>1.237131e+06</td>\n",
       "      <td>9486.121357</td>\n",
       "      <td>1.293661e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>682.968140</td>\n",
       "      <td>33.869507</td>\n",
       "      <td>523.140560</td>\n",
       "      <td>36.923040</td>\n",
       "      <td>628.774400</td>\n",
       "      <td>31.367565</td>\n",
       "      <td>1147.502400</td>\n",
       "      <td>34.130856</td>\n",
       "      <td>914.816200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        chroma_stft_mean  chroma_stft_var     rms_mean       rms_var  \\\n",
       "count        9981.000000      9981.000000  9981.000000  9.981000e+03   \n",
       "unique               NaN              NaN          NaN           NaN   \n",
       "top                  NaN              NaN          NaN           NaN   \n",
       "freq                 NaN              NaN          NaN           NaN   \n",
       "mean            0.379964         0.084882     0.130039  2.672433e-03   \n",
       "std             0.090624         0.009675     0.068168  3.561532e-03   \n",
       "min             0.108073         0.015217     0.000947  4.055916e-08   \n",
       "25%             0.316037         0.079820     0.083223  6.285820e-04   \n",
       "50%             0.385163         0.085137     0.120488  1.500287e-03   \n",
       "75%             0.442906         0.091154     0.175334  3.113760e-03   \n",
       "max             0.751176         0.120717     0.440458  3.237973e-02   \n",
       "\n",
       "        spectral_centroid_mean  spectral_centroid_var  \\\n",
       "count              9981.000000           9.981000e+03   \n",
       "unique                     NaN                    NaN   \n",
       "top                        NaN                    NaN   \n",
       "freq                       NaN                    NaN   \n",
       "mean               2201.910957           4.159255e+05   \n",
       "std                 750.540439           4.339675e+05   \n",
       "min                 479.905803           2.161498e+03   \n",
       "25%                1634.097152           1.228336e+05   \n",
       "50%                2211.777107           2.643931e+05   \n",
       "75%                2713.457812           5.612200e+05   \n",
       "max                5432.278843           4.801847e+06   \n",
       "\n",
       "        spectral_bandwidth_mean  spectral_bandwidth_var  rolloff_mean  \\\n",
       "count               9981.000000            9.981000e+03   9981.000000   \n",
       "unique                      NaN                     NaN           NaN   \n",
       "top                         NaN                     NaN           NaN   \n",
       "freq                        NaN                     NaN           NaN   \n",
       "mean                2244.562460            1.183121e+05   4571.568401   \n",
       "std                  541.420376            1.002501e+05   1639.481644   \n",
       "min                  499.577102            1.295350e+03    673.906438   \n",
       "25%                 1890.204723            4.941410e+04   3389.905912   \n",
       "50%                 2233.071916            9.037122e+04   4634.773513   \n",
       "75%                 2590.295338            1.578929e+05   5597.307692   \n",
       "max                 3708.279663            1.237131e+06   9486.121357   \n",
       "\n",
       "         rolloff_var  ...   mfcc16_var  mfcc17_mean   mfcc17_var  mfcc18_mean  \\\n",
       "count   9.981000e+03  ...  9981.000000  9981.000000  9981.000000  9981.000000   \n",
       "unique           NaN  ...          NaN          NaN          NaN          NaN   \n",
       "top              NaN  ...          NaN          NaN          NaN          NaN   \n",
       "freq             NaN  ...          NaN          NaN          NaN          NaN   \n",
       "mean    1.623468e+06  ...    49.879672    -4.193187    51.838396     0.724376   \n",
       "std     1.482634e+06  ...    34.358130     5.668784    36.301829     5.175797   \n",
       "min     1.130834e+03  ...     1.343237   -27.932222     1.531855   -20.749748   \n",
       "25%     5.562385e+05  ...    29.521790    -7.948162    29.821220    -2.524088   \n",
       "50%     1.155826e+06  ...    41.505714    -4.444725    42.235080     0.730935   \n",
       "75%     2.251497e+06  ...    59.062060    -0.731065    61.467620     3.871771   \n",
       "max     1.293661e+07  ...   682.968140    33.869507   523.140560    36.923040   \n",
       "\n",
       "         mfcc18_var  mfcc19_mean   mfcc19_var  mfcc20_mean   mfcc20_var  genre  \n",
       "count   9981.000000  9981.000000  9981.000000  9981.000000  9981.000000   9981  \n",
       "unique          NaN          NaN          NaN          NaN          NaN     10  \n",
       "top             NaN          NaN          NaN          NaN          NaN  blues  \n",
       "freq            NaN          NaN          NaN          NaN          NaN   1000  \n",
       "mean      52.343694    -2.497094    54.811697    -0.929246    57.142098    NaN  \n",
       "std       38.067790     5.107192    41.505894     5.247202    46.342797    NaN  \n",
       "min        3.445752   -27.359076     3.147765   -35.614895     0.253587    NaN  \n",
       "25%       29.405123    -5.734853    30.384860    -4.012720    29.925747    NaN  \n",
       "50%       41.686157    -2.700388    43.264107    -1.045194    44.173588    NaN  \n",
       "75%       61.854343     0.521315    65.165120     2.192562    68.000710    NaN  \n",
       "max      628.774400    31.367565  1147.502400    34.130856   914.816200    NaN  \n",
       "\n",
       "[11 rows x 58 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean the 'tempo' column\n",
    "data['tempo'] = data['tempo'].str.strip('[]').astype(float)\n",
    "\n",
    "# Verify the changes\n",
    "data.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ab3cbc",
   "metadata": {},
   "source": [
    "## Begin Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4bc2053",
   "metadata": {},
   "source": [
    "Apply the low pass filter through use of a moving average with a window size of 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9d39f937",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_moving_average_filter(df, window_size=3):\n",
    "    feature_columns = df.columns.difference(['genre'])\n",
    "    df[feature_columns] = df[feature_columns].rolling(window=window_size, min_periods=1).mean()\n",
    "    return df\n",
    "\n",
    "data = apply_moving_average_filter(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae3885d",
   "metadata": {},
   "source": [
    "## Shuffle and Split data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc411a3b",
   "metadata": {},
   "source": [
    "Split data into training and testing sets (70/30)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "856874ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features and target variable\n",
    "X = np.array(data.iloc[:, :-1], dtype=float)\n",
    "y = data.iloc[:, -1]\n",
    "\n",
    "# Split the dataset with 70% for training set and 30% for test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a3426b",
   "metadata": {},
   "source": [
    "## Normalize the data set and encode the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1f882bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Encode the target labels\n",
    "encoder = LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd999c8f",
   "metadata": {},
   "source": [
    "## Learning curves "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f513d331",
   "metadata": {},
   "source": [
    "Learning curve function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "31ea6238",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(estimator, title, X, y, cv=None, n_jobs=None):\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    train_sizes, train_scores, test_scores = learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=np.linspace(.1, 1.0, 5))\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d089132f",
   "metadata": {},
   "source": [
    "## Model initialization and hyper parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab68640",
   "metadata": {},
   "source": [
    "Define function for model train and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "58f0c0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model training and evaluation function with cross-validation\n",
    "def train_and_evaluate_model(model, param_grid):\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    # Cross-validation\n",
    "    cv_scores = cross_val_score(best_model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    print(f'Cross-validation scores: {cv_scores}')\n",
    "    print(f'Mean cross-validation score: {np.mean(cv_scores)}')\n",
    "\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, target_names=encoder.classes_)\n",
    "    return best_model, accuracy, report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d75621",
   "metadata": {},
   "source": [
    "Random Forest Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fd683e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_param_grid = {\n",
    "    'n_estimators': [100, 250, 1000],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_best_model, rf_accuracy, rf_report = train_and_evaluate_model(rf_model, rf_param_grid)\n",
    "print(\"Random Forest Accuracy:\", rf_accuracy)\n",
    "print(\"Random Forest Classification Report:\\n\", rf_report)\n",
    "\n",
    "plot_learning_curve(rf_best_model, \"Learning Curves (Random Forest)\", X, y, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4aedfa3",
   "metadata": {},
   "source": [
    "Support Vector Machine Model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb794e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': [1, 0.1, 0.01, 0.001],\n",
    "    'kernel': ['rbf', 'linear']\n",
    "}\n",
    "svm_model = SVC()\n",
    "svm_best_model, svm_accuracy, svm_report = train_and_evaluate_model(svm_model, svm_param_grid)\n",
    "print(\"SVM Accuracy:\", svm_accuracy)\n",
    "print(\"SVM Classification Report:\\n\", svm_report)\n",
    "\n",
    "plot_learning_curve(svm_best_model, \"Learning Curves (SVM)\", X, y, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86a77d4",
   "metadata": {},
   "source": [
    "Gradient Boost Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7491ad4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.5],\n",
    "    'max_depth': [3, 5, 7]\n",
    "}\n",
    "gb_model = GradientBoostingClassifier()\n",
    "gb_best_model, gb_accuracy, gb_report = train_and_evaluate_model(gb_model, gb_param_grid)\n",
    "print(\"Gradient Boosting Accuracy:\", gb_accuracy)\n",
    "print(\"Gradient Boosting Classification Report:\\n\", gb_report)\n",
    "\n",
    "plot_learning_curve(gb_best_model, \"Learning Curves (Gradient Boosting)\", X, y, cv=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b8e642",
   "metadata": {},
   "source": [
    "KNeighbours Model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9673d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "knn_model = KNeighborsClassifier()\n",
    "knn_best_model, knn_accuracy, knn_report = train_and_evaluate_model(knn_model, knn_param_grid)\n",
    "print(\"KNeighbors Accuracy:\", knn_accuracy)\n",
    "print(\"KNeighbors Classification Report:\\n\", knn_report)\n",
    "\n",
    "plot_learning_curve(knn_best_model, \"Learning Curves (KNN)\", X, y, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4838709",
   "metadata": {},
   "source": [
    "## Save models for future use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44455683",
   "metadata": {},
   "source": [
    "Use library to save model for export/import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f3d699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best models\n",
    "joblib.dump(rf_best_model, 'outputs/rf_best_model.pkl')\n",
    "joblib.dump(svm_best_model, 'outputs/svm_best_model.pkl')\n",
    "joblib.dump(gb_best_model, 'outputs/gb_best_model.pkl')\n",
    "joblib.dump(knn_best_model, 'outputs/knn_best_model.pkl')\n",
    "\n",
    "# Save the scaler and encoder\n",
    "joblib.dump(scaler, 'outputs/scaler.pkl')\n",
    "joblib.dump(encoder, 'outputs/encoder.pkl')\n",
    "\n",
    "# Save the scaled data and encoded labels\n",
    "joblib.dump(X_train, 'outputs/X_train.pkl')\n",
    "joblib.dump(X_test, 'outputs/X_test.pkl')\n",
    "joblib.dump(y_train, 'outputs/y_train.pkl')\n",
    "joblib.dump(y_test, 'outputs/y_test.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490e9939",
   "metadata": {},
   "source": [
    "## External validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78f8ebe",
   "metadata": {},
   "source": [
    "Preprocess the external data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6e3be77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load external data\n",
    "external_data = pd.read_csv('file_features.csv')\n",
    "external_data = external_data.drop(columns=['filename', 'start', 'end'])\n",
    "\n",
    "# Clean the 'tempo' column\n",
    "external_data['tempo'] = external_data['tempo'].str.strip('[]').astype(float)\n",
    "\n",
    "# Apply the same moving average filter\n",
    "external_data = apply_moving_average_filter(external_data)\n",
    "\n",
    "# Separate features\n",
    "X_external = scaler.transform(np.array(external_data.iloc[:, :], dtype=float))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6691ee3d",
   "metadata": {},
   "source": [
    "Apply the best models on the external data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "57eb0269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Predictions on External Data:\n",
      "['hiphop', 'hiphop', 'hiphop', 'hiphop', 'hiphop', 'hiphop', 'hiphop', 'hiphop']\n",
      "SVM Predictions on External Data:\n",
      "['hiphop', 'hiphop', 'hiphop', 'hiphop', 'hiphop', 'hiphop', 'hiphop', 'hiphop']\n",
      "Gradient Boosting Predictions on External Data:\n",
      "['hiphop', 'hiphop', 'hiphop', 'hiphop', 'hiphop', 'hiphop', 'hiphop', 'pop']\n",
      "K-Nearest Neighbors Predictions on External Data:\n",
      "['reggae', 'pop', 'pop', 'hiphop', 'hiphop', 'reggae', 'reggae', 'reggae']\n"
     ]
    }
   ],
   "source": [
    "# Load the best models\n",
    "rf_best_model = joblib.load('outputs/rf_best_model.pkl')\n",
    "svm_best_model = joblib.load('outputs/svm_best_model.pkl')\n",
    "gb_best_model = joblib.load('outputs/gb_best_model.pkl')\n",
    "knn_best_model = joblib.load('outputs/knn_best_model.pkl')\n",
    "\n",
    "# Define a function to evaluate a model on unlabeled external data\n",
    "def evaluate_model_on_external_data(model, X_ext, model_name):\n",
    "    y_pred = model.predict(X_ext)\n",
    "    # Map predicted numbers to genre names\n",
    "    y_pred_genre = [genres[pred] for pred in y_pred]\n",
    "    print(f\"{model_name} Predictions on External Data:\")\n",
    "    print(y_pred_genre)\n",
    "\n",
    "# Evaluate each model\n",
    "evaluate_model_on_external_data(rf_best_model, X_external, \"Random Forest\")\n",
    "evaluate_model_on_external_data(svm_best_model, X_external, \"SVM\")\n",
    "evaluate_model_on_external_data(gb_best_model, X_external, \"Gradient Boosting\")\n",
    "evaluate_model_on_external_data(knn_best_model, X_external, \"K-Nearest Neighbors\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
