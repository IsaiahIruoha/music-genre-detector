{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b2fae50",
   "metadata": {},
   "source": [
    "# Supervised Learning Music Genre Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e886f4ed",
   "metadata": {},
   "source": [
    "## Import Statements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b590e7",
   "metadata": {},
   "source": [
    "Start by importing necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22138a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import pandas as pd\n",
    "from pydub import AudioSegment\n",
    "import tempfile\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import soundfile as sf\n",
    "import joblib\n",
    "import librosa.display\n",
    "from skimage import io\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a0285f",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e9fb7d",
   "metadata": {},
   "source": [
    "Convert to MP3 function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e3d8b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert MP3 to WAV\n",
    "def convert_mp3_to_wav(mp3_file):\n",
    "    try:\n",
    "        sound = AudioSegment.from_mp3(mp3_file)\n",
    "        wav_file = tempfile.mktemp(suffix='.wav')\n",
    "        sound.export(wav_file, format=\"wav\")\n",
    "        return wav_file\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting {mp3_file} to WAV: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e514b2",
   "metadata": {},
   "source": [
    "Feature extraction from a segment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5aa55f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract features from an audio segment\n",
    "def extract_features_from_segment(y, sr, start_time, end_time):\n",
    "    segment = y[start_time:end_time]\n",
    "\n",
    "    chroma_stft = librosa.feature.chroma_stft(y=segment, sr=sr)\n",
    "    rms = librosa.feature.rms(y=segment)\n",
    "    spectral_centroid = librosa.feature.spectral_centroid(y=segment, sr=sr)\n",
    "    spectral_bandwidth = librosa.feature.spectral_bandwidth(y=segment, sr=sr)\n",
    "    rolloff = librosa.feature.spectral_rolloff(y=segment, sr=sr)\n",
    "    zero_crossing_rate = librosa.feature.zero_crossing_rate(y=segment)\n",
    "    harmony, perceptr = librosa.effects.hpss(segment)\n",
    "    tempo, _ = librosa.beat.beat_track(y=segment, sr=sr)\n",
    "    mfcc = librosa.feature.mfcc(y=segment, sr=sr, n_mfcc=20)\n",
    "\n",
    "    features = {\n",
    "        'chroma_stft_mean': chroma_stft.mean() if chroma_stft.size else 0,\n",
    "        'chroma_stft_var': chroma_stft.var() if chroma_stft.size else 0,\n",
    "        'rms_mean': rms.mean() if rms.size else 0,\n",
    "        'rms_var': rms.var() if rms.size else 0,\n",
    "        'spectral_centroid_mean': spectral_centroid.mean() if spectral_centroid.size else 0,\n",
    "        'spectral_centroid_var': spectral_centroid.var() if spectral_centroid.size else 0,\n",
    "        'spectral_bandwidth_mean': spectral_bandwidth.mean() if spectral_bandwidth.size else 0,\n",
    "        'spectral_bandwidth_var': spectral_bandwidth.var() if spectral_bandwidth.size else 0,\n",
    "        'rolloff_mean': rolloff.mean() if rolloff.size else 0,\n",
    "        'rolloff_var': rolloff.var() if rolloff.size else 0,\n",
    "        'zero_crossing_rate_mean': zero_crossing_rate.mean() if zero_crossing_rate.size else 0,\n",
    "        'zero_crossing_rate_var': zero_crossing_rate.var() if zero_crossing_rate.size else 0,\n",
    "        'harmony_mean': harmony.mean() if harmony.size else 0,\n",
    "        'harmony_var': harmony.var() if harmony.size else 0,\n",
    "        'perceptr_mean': perceptr.mean() if perceptr.size else 0,\n",
    "        'perceptr_var': perceptr.var() if perceptr.size else 0,\n",
    "        'tempo': tempo,\n",
    "    }\n",
    "\n",
    "    for i in range(1, 21):\n",
    "        features[f'mfcc{i}_mean'] = mfcc[i-1].mean() if mfcc.shape[0] >= i else 0\n",
    "        features[f'mfcc{i}_var'] = mfcc[i-1].var() if mfcc.shape[0] >= i else 0\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcf0655",
   "metadata": {},
   "source": [
    "Load audio helpfer function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "913bcfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load audio file\n",
    "def load_audio(file_path):\n",
    "    try:\n",
    "        y, sr = librosa.load(file_path, sr=None)\n",
    "    except sf.LibsndfileError:\n",
    "        print(f\"LibsndfileError: {file_path}\")\n",
    "        return None, None\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {file_path}: {e}\")\n",
    "        return None, None\n",
    "    return y, sr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19ba2e3",
   "metadata": {},
   "source": [
    "Generate spectrogram helper function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a56d7aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate and save spectrogram\n",
    "def generate_spectrogram(y, sr, file_path):\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
    "    S_dB = librosa.power_to_db(S, ref=np.max)\n",
    "    spectrogram_file = os.path.splitext(file_path)[0] + '_spectrogram.png'\n",
    "    librosa.display.specshow(S_dB, sr=sr, x_axis='time', y_axis='mel')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title('Mel-frequency spectrogram')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(spectrogram_file)\n",
    "    plt.close()\n",
    "    return spectrogram_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b33bf9d",
   "metadata": {},
   "source": [
    "Extract features from spectrogram. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a183c14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract numerical features from the spectrogram\n",
    "def extract_spectrogram_features(spectrogram_path):\n",
    "    try:\n",
    "        image = io.imread(spectrogram_path, as_gray=True)\n",
    "        image_resized = resize(image, (128, 128))  # Resize to a fixed size\n",
    "        features = image_resized.flatten()  # Flatten to 1D array\n",
    "        return features\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting spectrogram features from {spectrogram_path}: {e}\")\n",
    "        return np.zeros(128*128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa5f717",
   "metadata": {},
   "source": [
    "Segment data and call feature extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75e1c6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract features from an audio file\n",
    "def extract_features(audio_file, segment_duration=3):\n",
    "    try:\n",
    "        y, sr = load_audio(audio_file)\n",
    "        if y is None:\n",
    "            return []\n",
    "\n",
    "        total_duration = len(y) / sr\n",
    "        segment_length = int(sr * segment_duration)\n",
    "\n",
    "        features_list = []\n",
    "\n",
    "        for start in range(0, len(y), segment_length):\n",
    "            end = start + segment_length\n",
    "            if end <= len(y):\n",
    "                segment_features = extract_features_from_segment(y, sr, start, end)\n",
    "                #spectrogram_path = generate_spectrogram(y[start:end], sr, audio_file)\n",
    "                #spectrogram_features = extract_spectrogram_features(spectrogram_path)\n",
    "                #all_features = {**segment_features, **{f'spec_{i}': val for i, val in enumerate(spectrogram_features)}}\n",
    "                all_features = segment_features\n",
    "                all_features['filename'] = os.path.basename(audio_file)\n",
    "                all_features['start'] = start / sr\n",
    "                all_features['end'] = end / sr\n",
    "                features_list.append(all_features)\n",
    "\n",
    "        return features_list\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting features from {audio_file}: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3851f10",
   "metadata": {},
   "source": [
    "## Define Data Paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96da33c7",
   "metadata": {},
   "source": [
    "Specify the paths to the CSV files containing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0784aec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of genres\n",
    "genres = [\"blues\", \"classical\", \"country\", \"disco\", \"hiphop\", \"jazz\", \"metal\", \"pop\", \"reggae\", \"rock\"]\n",
    "\n",
    "# Base folder containing genre subfolders\n",
    "base_folder_path = '/Users/isaiah/Desktop/Career/Projects/music-genre-detector/GTZan/genres_original'\n",
    "\n",
    "# Create a directory to save spectrograms\n",
    "spectrogram_base_path = '/Users/isaiah/Desktop/Career/Projects/music-genre-detector/spectrograms'\n",
    "os.makedirs(spectrogram_base_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953974b0",
   "metadata": {},
   "source": [
    "## Process Input Audio Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0d4edc",
   "metadata": {},
   "source": [
    "Process input files and label the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec7af356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process a folder of audio files\n",
    "def process_audio_folder(folder_path, genre_label):\n",
    "    results = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.wav') or filename.endswith('.mp3'):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            if filename.endswith('.mp3'):\n",
    "                file_path = convert_mp3_to_wav(file_path)\n",
    "            features_list = extract_features(file_path)\n",
    "            for features in features_list:\n",
    "                features['genre'] = genre_label\n",
    "                results.append(features)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a872c4cd",
   "metadata": {},
   "source": [
    "## Create Singular CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9fc8b6",
   "metadata": {},
   "source": [
    "Aggregate results of the feature extraction into a singular CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7412610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing genre: blues\n",
      "Completed processing genre: blues\n",
      "Processing genre: classical\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing genre: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgenre\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m folder_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(base_folder_path, genre)\n\u001b[0;32m----> 6\u001b[0m genre_results \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_audio_folder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfolder_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenre\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m all_results\u001b[38;5;241m.\u001b[39mextend(genre_results)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompleted processing genre: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgenre\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[9], line 9\u001b[0m, in \u001b[0;36mprocess_audio_folder\u001b[0;34m(folder_path, genre_label)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.mp3\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m      8\u001b[0m     file_path \u001b[38;5;241m=\u001b[39m convert_mp3_to_wav(file_path)\n\u001b[0;32m----> 9\u001b[0m features_list \u001b[38;5;241m=\u001b[39m \u001b[43mextract_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m features \u001b[38;5;129;01min\u001b[39;00m features_list:\n\u001b[1;32m     11\u001b[0m     features[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenre\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m genre_label\n",
      "Cell \u001b[0;32mIn[7], line 16\u001b[0m, in \u001b[0;36mextract_features\u001b[0;34m(audio_file, segment_duration)\u001b[0m\n\u001b[1;32m     14\u001b[0m end \u001b[38;5;241m=\u001b[39m start \u001b[38;5;241m+\u001b[39m segment_length\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(y):\n\u001b[0;32m---> 16\u001b[0m     segment_features \u001b[38;5;241m=\u001b[39m \u001b[43mextract_features_from_segment\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m#spectrogram_path = generate_spectrogram(y[start:end], sr, audio_file)\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m#spectrogram_features = extract_spectrogram_features(spectrogram_path)\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;66;03m#all_features = {**segment_features, **{f'spec_{i}': val for i, val in enumerate(spectrogram_features)}}\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     all_features \u001b[38;5;241m=\u001b[39m segment_features\n",
      "Cell \u001b[0;32mIn[3], line 12\u001b[0m, in \u001b[0;36mextract_features_from_segment\u001b[0;34m(y, sr, start_time, end_time)\u001b[0m\n\u001b[1;32m     10\u001b[0m zero_crossing_rate \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mfeature\u001b[38;5;241m.\u001b[39mzero_crossing_rate(y\u001b[38;5;241m=\u001b[39msegment)\n\u001b[1;32m     11\u001b[0m harmony, perceptr \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39meffects\u001b[38;5;241m.\u001b[39mhpss(segment)\n\u001b[0;32m---> 12\u001b[0m tempo, _ \u001b[38;5;241m=\u001b[39m \u001b[43mlibrosa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbeat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbeat_track\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msegment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m mfcc \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mfeature\u001b[38;5;241m.\u001b[39mmfcc(y\u001b[38;5;241m=\u001b[39msegment, sr\u001b[38;5;241m=\u001b[39msr, n_mfcc\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n\u001b[1;32m     15\u001b[0m features \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchroma_stft_mean\u001b[39m\u001b[38;5;124m'\u001b[39m: chroma_stft\u001b[38;5;241m.\u001b[39mmean() \u001b[38;5;28;01mif\u001b[39;00m chroma_stft\u001b[38;5;241m.\u001b[39msize \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchroma_stft_var\u001b[39m\u001b[38;5;124m'\u001b[39m: chroma_stft\u001b[38;5;241m.\u001b[39mvar() \u001b[38;5;28;01mif\u001b[39;00m chroma_stft\u001b[38;5;241m.\u001b[39msize \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtempo\u001b[39m\u001b[38;5;124m'\u001b[39m: tempo,\n\u001b[1;32m     33\u001b[0m }\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ELEC292/lib/python3.9/site-packages/librosa/beat.py:245\u001b[0m, in \u001b[0;36mbeat_track\u001b[0;34m(y, sr, onset_envelope, hop_length, start_bpm, tightness, trim, bpm, prior, units, sparse)\u001b[0m\n\u001b[1;32m    240\u001b[0m bpm_expanded \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mexpand_to(_bpm,\n\u001b[1;32m    241\u001b[0m                               ndim\u001b[38;5;241m=\u001b[39monset_envelope\u001b[38;5;241m.\u001b[39mndim,\n\u001b[1;32m    242\u001b[0m                               axes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mrange\u001b[39m(_bpm\u001b[38;5;241m.\u001b[39mndim))\n\u001b[1;32m    244\u001b[0m \u001b[38;5;66;03m# Then, run the tracker\u001b[39;00m\n\u001b[0;32m--> 245\u001b[0m beats \u001b[38;5;241m=\u001b[39m \u001b[43m__beat_tracker\u001b[49m\u001b[43m(\u001b[49m\u001b[43monset_envelope\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbpm_expanded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mhop_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtightness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparse:\n\u001b[1;32m    248\u001b[0m     beats \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mflatnonzero(beats)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ELEC292/lib/python3.9/site-packages/librosa/beat.py:494\u001b[0m, in \u001b[0;36m__beat_tracker\u001b[0;34m(onset_envelope, bpm, frame_rate, tightness, trim)\u001b[0m\n\u001b[1;32m    491\u001b[0m backlink, cumscore \u001b[38;5;241m=\u001b[39m __beat_track_dp(localscore, frames_per_beat, tightness)\n\u001b[1;32m    493\u001b[0m \u001b[38;5;66;03m# Reconstruct the beat path from backlinks\u001b[39;00m\n\u001b[0;32m--> 494\u001b[0m tail \u001b[38;5;241m=\u001b[39m \u001b[43m__last_beat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcumscore\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    495\u001b[0m beats \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros_like(onset_envelope, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n\u001b[1;32m    496\u001b[0m __dp_backtrack(backlink, tail, beats)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ELEC292/lib/python3.9/site-packages/librosa/beat.py:647\u001b[0m, in \u001b[0;36m__last_beat\u001b[0;34m(cumscore)\u001b[0m\n\u001b[1;32m    645\u001b[0m mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m~\u001b[39mutil\u001b[38;5;241m.\u001b[39mlocalmax(cumscore, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    646\u001b[0m masked_scores \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mma\u001b[38;5;241m.\u001b[39mmasked_array(data\u001b[38;5;241m=\u001b[39mcumscore, mask\u001b[38;5;241m=\u001b[39mmask)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m--> 647\u001b[0m medians \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmedian\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmasked_scores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    648\u001b[0m thresholds \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mma\u001b[38;5;241m.\u001b[39mgetdata(medians)\n\u001b[1;32m    650\u001b[0m \u001b[38;5;66;03m# Also find the last beat positions\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ELEC292/lib/python3.9/site-packages/numpy/ma/extras.py:734\u001b[0m, in \u001b[0;36mmedian\u001b[0;34m(a, axis, out, overwrite_input, keepdims)\u001b[0m\n\u001b[1;32m    731\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    732\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m m\n\u001b[0;32m--> 734\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ureduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_median\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    735\u001b[0m \u001b[43m                \u001b[49m\u001b[43moverwrite_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite_input\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ELEC292/lib/python3.9/site-packages/numpy/lib/function_base.py:3823\u001b[0m, in \u001b[0;36m_ureduce\u001b[0;34m(a, func, keepdims, **kwargs)\u001b[0m\n\u001b[1;32m   3820\u001b[0m             index_out \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, ) \u001b[38;5;241m*\u001b[39m nd\n\u001b[1;32m   3821\u001b[0m             kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mout\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m out[(\u001b[38;5;28mEllipsis\u001b[39m, ) \u001b[38;5;241m+\u001b[39m index_out]\n\u001b[0;32m-> 3823\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3825\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3826\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ELEC292/lib/python3.9/site-packages/numpy/ma/extras.py:775\u001b[0m, in \u001b[0;36m_median\u001b[0;34m(a, axis, out, overwrite_input)\u001b[0m\n\u001b[1;32m    773\u001b[0m     s \u001b[38;5;241m=\u001b[39m mid\u001b[38;5;241m.\u001b[39msum(out\u001b[38;5;241m=\u001b[39mout)\n\u001b[1;32m    774\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m odd:\n\u001b[0;32m--> 775\u001b[0m         s \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrue_divide\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcasting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msafe\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    776\u001b[0m     s \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlib\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39m_median_nancheck(asorted, s, axis)\n\u001b[1;32m    777\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "all_results = []\n",
    "\n",
    "for genre in genres:\n",
    "    print(f\"Processing genre: {genre}\")\n",
    "    folder_path = os.path.join(base_folder_path, genre)\n",
    "    genre_results = process_audio_folder(folder_path, genre)\n",
    "    all_results.extend(genre_results)\n",
    "    print(f\"Completed processing genre: {genre}\")\n",
    "\n",
    "print(\"Writing results to CSV file...\")\n",
    "df = pd.DataFrame(all_results)\n",
    "csv_file_path = '/Users/isaiah/Desktop/Career/Projects/music-genre-detector/all_genres_audio_features.csv'\n",
    "df.to_csv(csv_file_path, index=False)\n",
    "print(\"CSV file generation completed.\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f0d23c",
   "metadata": {},
   "source": [
    "## Examine Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f555dd",
   "metadata": {},
   "source": [
    "Gain insights into data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cf96d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chroma_stft_mean</th>\n",
       "      <th>chroma_stft_var</th>\n",
       "      <th>rms_mean</th>\n",
       "      <th>rms_var</th>\n",
       "      <th>spectral_centroid_mean</th>\n",
       "      <th>spectral_centroid_var</th>\n",
       "      <th>spectral_bandwidth_mean</th>\n",
       "      <th>spectral_bandwidth_var</th>\n",
       "      <th>rolloff_mean</th>\n",
       "      <th>rolloff_var</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc17_mean</th>\n",
       "      <th>mfcc17_var</th>\n",
       "      <th>mfcc18_mean</th>\n",
       "      <th>mfcc18_var</th>\n",
       "      <th>mfcc19_mean</th>\n",
       "      <th>mfcc19_var</th>\n",
       "      <th>mfcc20_mean</th>\n",
       "      <th>mfcc20_var</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9981.000000</td>\n",
       "      <td>9981.000000</td>\n",
       "      <td>9981.000000</td>\n",
       "      <td>9.981000e+03</td>\n",
       "      <td>9981.000000</td>\n",
       "      <td>9.981000e+03</td>\n",
       "      <td>9981.000000</td>\n",
       "      <td>9.981000e+03</td>\n",
       "      <td>9981.000000</td>\n",
       "      <td>9.981000e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>9981.000000</td>\n",
       "      <td>9981.000000</td>\n",
       "      <td>9981.000000</td>\n",
       "      <td>9981.000000</td>\n",
       "      <td>9981.000000</td>\n",
       "      <td>9981.000000</td>\n",
       "      <td>9981.000000</td>\n",
       "      <td>9981.000000</td>\n",
       "      <td>9981.000000</td>\n",
       "      <td>9981.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.379964</td>\n",
       "      <td>0.084882</td>\n",
       "      <td>0.130039</td>\n",
       "      <td>2.672434e-03</td>\n",
       "      <td>2201.910957</td>\n",
       "      <td>4.159255e+05</td>\n",
       "      <td>2244.562460</td>\n",
       "      <td>1.183121e+05</td>\n",
       "      <td>4571.568401</td>\n",
       "      <td>1.623468e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.193187</td>\n",
       "      <td>51.838394</td>\n",
       "      <td>0.724376</td>\n",
       "      <td>52.343689</td>\n",
       "      <td>-2.497094</td>\n",
       "      <td>54.811691</td>\n",
       "      <td>-0.929246</td>\n",
       "      <td>57.142101</td>\n",
       "      <td>13.487827</td>\n",
       "      <td>16.487827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.090624</td>\n",
       "      <td>0.009675</td>\n",
       "      <td>0.068168</td>\n",
       "      <td>3.561535e-03</td>\n",
       "      <td>750.540439</td>\n",
       "      <td>4.339675e+05</td>\n",
       "      <td>541.420376</td>\n",
       "      <td>1.002501e+05</td>\n",
       "      <td>1639.481644</td>\n",
       "      <td>1.482634e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>5.668772</td>\n",
       "      <td>36.301769</td>\n",
       "      <td>5.175787</td>\n",
       "      <td>38.067753</td>\n",
       "      <td>5.107198</td>\n",
       "      <td>41.505917</td>\n",
       "      <td>5.247203</td>\n",
       "      <td>46.342815</td>\n",
       "      <td>8.611614</td>\n",
       "      <td>8.611614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.108073</td>\n",
       "      <td>0.015217</td>\n",
       "      <td>0.000947</td>\n",
       "      <td>4.055916e-08</td>\n",
       "      <td>479.905803</td>\n",
       "      <td>2.161498e+03</td>\n",
       "      <td>499.577101</td>\n",
       "      <td>1.295350e+03</td>\n",
       "      <td>673.906438</td>\n",
       "      <td>1.130834e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>-27.932220</td>\n",
       "      <td>1.531856</td>\n",
       "      <td>-20.749746</td>\n",
       "      <td>3.445751</td>\n",
       "      <td>-27.359076</td>\n",
       "      <td>3.147764</td>\n",
       "      <td>-35.614895</td>\n",
       "      <td>0.253587</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.316037</td>\n",
       "      <td>0.079820</td>\n",
       "      <td>0.083223</td>\n",
       "      <td>6.285820e-04</td>\n",
       "      <td>1634.097151</td>\n",
       "      <td>1.228336e+05</td>\n",
       "      <td>1890.204723</td>\n",
       "      <td>4.941410e+04</td>\n",
       "      <td>3389.905912</td>\n",
       "      <td>5.562385e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.948162</td>\n",
       "      <td>29.821222</td>\n",
       "      <td>-2.524088</td>\n",
       "      <td>29.405123</td>\n",
       "      <td>-5.734853</td>\n",
       "      <td>30.384863</td>\n",
       "      <td>-4.012720</td>\n",
       "      <td>29.925747</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.385163</td>\n",
       "      <td>0.085137</td>\n",
       "      <td>0.120488</td>\n",
       "      <td>1.500287e-03</td>\n",
       "      <td>2211.777107</td>\n",
       "      <td>2.643931e+05</td>\n",
       "      <td>2233.071917</td>\n",
       "      <td>9.037122e+04</td>\n",
       "      <td>4634.773513</td>\n",
       "      <td>1.155826e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.444726</td>\n",
       "      <td>42.235081</td>\n",
       "      <td>0.730936</td>\n",
       "      <td>41.686157</td>\n",
       "      <td>-2.700388</td>\n",
       "      <td>43.264107</td>\n",
       "      <td>-1.045194</td>\n",
       "      <td>44.173588</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.442906</td>\n",
       "      <td>0.091154</td>\n",
       "      <td>0.175334</td>\n",
       "      <td>3.113760e-03</td>\n",
       "      <td>2713.457812</td>\n",
       "      <td>5.612200e+05</td>\n",
       "      <td>2590.295338</td>\n",
       "      <td>1.578929e+05</td>\n",
       "      <td>5597.307692</td>\n",
       "      <td>2.251497e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.731065</td>\n",
       "      <td>61.467625</td>\n",
       "      <td>3.871771</td>\n",
       "      <td>61.854340</td>\n",
       "      <td>0.521315</td>\n",
       "      <td>65.165131</td>\n",
       "      <td>2.192562</td>\n",
       "      <td>68.000710</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.751176</td>\n",
       "      <td>0.120717</td>\n",
       "      <td>0.440458</td>\n",
       "      <td>3.237973e-02</td>\n",
       "      <td>5432.278842</td>\n",
       "      <td>4.801847e+06</td>\n",
       "      <td>3708.279664</td>\n",
       "      <td>1.237131e+06</td>\n",
       "      <td>9486.121357</td>\n",
       "      <td>1.293661e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>33.869503</td>\n",
       "      <td>523.140564</td>\n",
       "      <td>36.923035</td>\n",
       "      <td>628.774414</td>\n",
       "      <td>31.367567</td>\n",
       "      <td>1147.502441</td>\n",
       "      <td>34.130856</td>\n",
       "      <td>914.816223</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       chroma_stft_mean  chroma_stft_var     rms_mean       rms_var  \\\n",
       "count       9981.000000      9981.000000  9981.000000  9.981000e+03   \n",
       "mean           0.379964         0.084882     0.130039  2.672434e-03   \n",
       "std            0.090624         0.009675     0.068168  3.561535e-03   \n",
       "min            0.108073         0.015217     0.000947  4.055916e-08   \n",
       "25%            0.316037         0.079820     0.083223  6.285820e-04   \n",
       "50%            0.385163         0.085137     0.120488  1.500287e-03   \n",
       "75%            0.442906         0.091154     0.175334  3.113760e-03   \n",
       "max            0.751176         0.120717     0.440458  3.237973e-02   \n",
       "\n",
       "       spectral_centroid_mean  spectral_centroid_var  spectral_bandwidth_mean  \\\n",
       "count             9981.000000           9.981000e+03              9981.000000   \n",
       "mean              2201.910957           4.159255e+05              2244.562460   \n",
       "std                750.540439           4.339675e+05               541.420376   \n",
       "min                479.905803           2.161498e+03               499.577101   \n",
       "25%               1634.097151           1.228336e+05              1890.204723   \n",
       "50%               2211.777107           2.643931e+05              2233.071917   \n",
       "75%               2713.457812           5.612200e+05              2590.295338   \n",
       "max               5432.278842           4.801847e+06              3708.279664   \n",
       "\n",
       "       spectral_bandwidth_var  rolloff_mean   rolloff_var  ...  mfcc17_mean  \\\n",
       "count            9.981000e+03   9981.000000  9.981000e+03  ...  9981.000000   \n",
       "mean             1.183121e+05   4571.568401  1.623468e+06  ...    -4.193187   \n",
       "std              1.002501e+05   1639.481644  1.482634e+06  ...     5.668772   \n",
       "min              1.295350e+03    673.906438  1.130834e+03  ...   -27.932220   \n",
       "25%              4.941410e+04   3389.905912  5.562385e+05  ...    -7.948162   \n",
       "50%              9.037122e+04   4634.773513  1.155826e+06  ...    -4.444726   \n",
       "75%              1.578929e+05   5597.307692  2.251497e+06  ...    -0.731065   \n",
       "max              1.237131e+06   9486.121357  1.293661e+07  ...    33.869503   \n",
       "\n",
       "        mfcc17_var  mfcc18_mean   mfcc18_var  mfcc19_mean   mfcc19_var  \\\n",
       "count  9981.000000  9981.000000  9981.000000  9981.000000  9981.000000   \n",
       "mean     51.838394     0.724376    52.343689    -2.497094    54.811691   \n",
       "std      36.301769     5.175787    38.067753     5.107198    41.505917   \n",
       "min       1.531856   -20.749746     3.445751   -27.359076     3.147764   \n",
       "25%      29.821222    -2.524088    29.405123    -5.734853    30.384863   \n",
       "50%      42.235081     0.730936    41.686157    -2.700388    43.264107   \n",
       "75%      61.467625     3.871771    61.854340     0.521315    65.165131   \n",
       "max     523.140564    36.923035   628.774414    31.367567  1147.502441   \n",
       "\n",
       "       mfcc20_mean   mfcc20_var        start          end  \n",
       "count  9981.000000  9981.000000  9981.000000  9981.000000  \n",
       "mean     -0.929246    57.142101    13.487827    16.487827  \n",
       "std       5.247203    46.342815     8.611614     8.611614  \n",
       "min     -35.614895     0.253587     0.000000     3.000000  \n",
       "25%      -4.012720    29.925747     6.000000     9.000000  \n",
       "50%      -1.045194    44.173588    12.000000    15.000000  \n",
       "75%       2.192562    68.000710    21.000000    24.000000  \n",
       "max      34.130856   914.816223    27.000000    30.000000  \n",
       "\n",
       "[8 rows x 58 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get summary statistics\n",
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58539520",
   "metadata": {},
   "source": [
    "Check for duplicates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703ac5dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No duplicates or null values found in data\n"
     ]
    }
   ],
   "source": [
    "def check_duplicates_or_nulls(data):\n",
    "    duplicates = data.duplicated().sum() > 0\n",
    "    nulls = data.isnull().sum().sum() > 0\n",
    "    return duplicates or nulls\n",
    "\n",
    "data = pd.read_csv(csv_file_path)\n",
    "if check_duplicates_or_nulls(data):\n",
    "    print('Duplicates or null values found in data')\n",
    "else:\n",
    "    print('No duplicates or null values found in data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae3885d",
   "metadata": {},
   "source": [
    "## Shuffle and Split data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc411a3b",
   "metadata": {},
   "source": [
    "Split data into training and testing sets (90/10)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856874ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling and splitting the data into training and testing sets...\n"
     ]
    }
   ],
   "source": [
    "# Shuffle and split the data into training and testing sets\n",
    "print(\"Shuffling and splitting the data into training and testing sets...\")\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['genre'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ab3cbc",
   "metadata": {},
   "source": [
    "## Begin Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4bc2053",
   "metadata": {},
   "source": [
    "Apply the low pass filter through use of a moving average with a window size of 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d39f937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply moving average filter\n",
    "def apply_moving_average_filter(df, window_size=3):\n",
    "    feature_columns = df.columns.difference(['filename', 'start', 'end', 'genre'])\n",
    "    df[feature_columns] = df[feature_columns].rolling(window=window_size, min_periods=1).mean()\n",
    "    return df\n",
    "\n",
    "train_df = apply_moving_average_filter(train_df)\n",
    "test_df = apply_moving_average_filter(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e58b73",
   "metadata": {},
   "source": [
    "## Z Score normalization is done to the extracted features "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d220a43",
   "metadata": {},
   "source": [
    "Using StandardScaler to properly normalize the individual features for the train and test set, converting back to data frames upon completion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07169375",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Apply z-score normalization\n",
    "def apply_zscore_normalization(train_df, test_df):\n",
    "    feature_columns = train_df.columns.difference(['filename', 'start', 'end', 'genre'])\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    # Fit the scaler on the training data\n",
    "    train_df[feature_columns] = scaler.fit_transform(train_df[feature_columns])\n",
    "    \n",
    "    # Transform the testing data\n",
    "    test_df[feature_columns] = scaler.transform(test_df[feature_columns])\n",
    "    \n",
    "    return train_df, test_df\n",
    "\n",
    "train_df, test_df = apply_zscore_normalization(train_df, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06131463",
   "metadata": {},
   "source": [
    "## Separate features and labels for training and testing sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7435bd53",
   "metadata": {},
   "source": [
    "Must make sure that the labels and features themselves remain separate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0210e444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and labels for training and testing sets\n",
    "X_train = train_df.drop(columns=['filename', 'start', 'end', 'genre'])\n",
    "y_train = train_df['genre']\n",
    "X_test = test_df.drop(columns=['filename', 'start', 'end', 'genre'])\n",
    "y_test = test_df['genre']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1563a6",
   "metadata": {},
   "source": [
    "## Save train and test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17423aa6",
   "metadata": {},
   "source": [
    "save data to separate csv to visualize before feeding into the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d6e8f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and testing CSV files generation completed.\n"
     ]
    }
   ],
   "source": [
    "# Save the training and testing sets to separate CSV files\n",
    "train_features_csv_path = '/Users/isaiah/Desktop/Career/Projects/music-genre-detector/train_audio_features.csv'\n",
    "train_labels_csv_path = '/Users/isaiah/Desktop/Career/Projects/music-genre-detector/train_audio_labels.csv'\n",
    "test_features_csv_path = '/Users/isaiah/Desktop/Career/Projects/music-genre-detector/test_audio_features.csv'\n",
    "test_labels_csv_path = '/Users/isaiah/Desktop/Career/Projects/music-genre-detector/test_audio_labels.csv'\n",
    "\n",
    "X_train.to_csv(train_features_csv_path, index=False)\n",
    "y_train.to_csv(train_labels_csv_path, index=False)\n",
    "X_test.to_csv(test_features_csv_path, index=False)\n",
    "y_test.to_csv(test_labels_csv_path, index=False)\n",
    "print(\"Training and testing CSV files generation completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf094e6",
   "metadata": {},
   "source": [
    "## Call for Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbdf0e2",
   "metadata": {},
   "source": [
    "Retrieve the prepared data from the csv files to avoid the need to run the feature extraction cell every attempt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a11084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "train_features_csv_path = '/Users/isaiah/Desktop/Career/Projects/music-genre-detector/train_audio_features.csv'\n",
    "train_labels_csv_path = '/Users/isaiah/Desktop/Career/Projects/music-genre-detector/train_audio_labels.csv'\n",
    "test_features_csv_path = '/Users/isaiah/Desktop/Career/Projects/music-genre-detector/test_audio_features.csv'\n",
    "test_labels_csv_path = '/Users/isaiah/Desktop/Career/Projects/music-genre-detector/test_audio_labels.csv'\n",
    "\n",
    "# Load the datasets\n",
    "X_train = pd.read_csv(train_features_csv_path)\n",
    "y_train = pd.read_csv(train_labels_csv_path)['genre']\n",
    "X_test = pd.read_csv(test_features_csv_path)\n",
    "y_test = pd.read_csv(test_labels_csv_path)['genre']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d089132f",
   "metadata": {},
   "source": [
    "## Model initialization function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab68640",
   "metadata": {},
   "source": [
    "Setup for the model use and hyper parameterization phase. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f0c0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "y_train_encoded = encoder.fit_transform(y_train)\n",
    "y_test_encoded = encoder.transform(y_test)\n",
    "\n",
    "def train_and_evaluate_model(model, param_grid):\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
    "    grid_search.fit(X_train_scaled, y_train_encoded)\n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test_scaled)\n",
    "    accuracy = accuracy_score(y_test_encoded, y_pred)\n",
    "    report = classification_report(y_test_encoded, y_pred, target_names=encoder.classes_)\n",
    "    return best_model, accuracy, report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d75621",
   "metadata": {},
   "source": [
    "Random Forest Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fd683e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[86], line 26\u001b[0m\n\u001b[1;32m     18\u001b[0m rf_param_grid \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m200\u001b[39m],\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_features\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msqrt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlog2\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_samples_leaf\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m4\u001b[39m]\n\u001b[1;32m     24\u001b[0m }\n\u001b[1;32m     25\u001b[0m rf_model \u001b[38;5;241m=\u001b[39m RandomForestClassifier()\n\u001b[0;32m---> 26\u001b[0m rf_best_model, rf_accuracy, rf_report \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_evaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrf_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrf_param_grid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRandom Forest Accuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m, rf_accuracy)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRandom Forest Classification Report:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, rf_report)\n",
      "Cell \u001b[0;32mIn[86], line 11\u001b[0m, in \u001b[0;36mtrain_and_evaluate_model\u001b[0;34m(model, param_grid)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_and_evaluate_model\u001b[39m(model, param_grid):\n\u001b[1;32m     10\u001b[0m     grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(model, param_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m     \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_encoded\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     best_model \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[1;32m     13\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m best_model\u001b[38;5;241m.\u001b[39mpredict(X_test_scaled)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ELEC292/lib/python3.9/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ELEC292/lib/python3.9/site-packages/sklearn/model_selection/_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    964\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    965\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    966\u001b[0m     )\n\u001b[1;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 970\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    974\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ELEC292/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1527\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1525\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1526\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1527\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ELEC292/lib/python3.9/site-packages/sklearn/model_selection/_search.py:916\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    909\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    912\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    913\u001b[0m         )\n\u001b[1;32m    914\u001b[0m     )\n\u001b[0;32m--> 916\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    931\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    936\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    937\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    938\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    939\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ELEC292/lib/python3.9/site-packages/sklearn/utils/parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     66\u001b[0m )\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ELEC292/lib/python3.9/site-packages/joblib/parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ELEC292/lib/python3.9/site-packages/joblib/parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ELEC292/lib/python3.9/site-packages/sklearn/utils/parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ELEC292/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:895\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    893\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    894\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 895\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    897\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    898\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    899\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ELEC292/lib/python3.9/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ELEC292/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:489\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    478\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    481\u001b[0m ]\n\u001b[1;32m    483\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 489\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ELEC292/lib/python3.9/site-packages/sklearn/utils/parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     66\u001b[0m )\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ELEC292/lib/python3.9/site-packages/joblib/parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ELEC292/lib/python3.9/site-packages/joblib/parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ELEC292/lib/python3.9/site-packages/sklearn/utils/parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ELEC292/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:192\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    190\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[0;32m--> 192\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    200\u001b[0m     tree\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[1;32m    201\u001b[0m         X,\n\u001b[1;32m    202\u001b[0m         y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    205\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[1;32m    206\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ELEC292/lib/python3.9/site-packages/sklearn/tree/_classes.py:472\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    462\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    463\u001b[0m         splitter,\n\u001b[1;32m    464\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    470\u001b[0m     )\n\u001b[0;32m--> 472\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    475\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rf_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_best_model, rf_accuracy, rf_report = train_and_evaluate_model(rf_model, rf_param_grid)\n",
    "print(\"Random Forest Accuracy:\", rf_accuracy)\n",
    "print(\"Random Forest Classification Report:\\n\", rf_report)\n",
    "\n",
    "svm_param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': [1, 0.1, 0.01, 0.001],\n",
    "    'kernel': ['rbf', 'linear']\n",
    "}\n",
    "svm_model = SVC()\n",
    "svm_best_model, svm_accuracy, svm_report = train_and_evaluate_model(svm_model, svm_param_grid)\n",
    "print(\"SVM Accuracy:\", svm_accuracy)\n",
    "print(\"SVM Classification Report:\\n\", svm_report)\n",
    "\n",
    "gb_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.5],\n",
    "    'max_depth': [3, 5, 7]\n",
    "}\n",
    "gb_model = GradientBoostingClassifier()\n",
    "gb_best_model, gb_accuracy, gb_report = train_and_evaluate_model(gb_model, gb_param_grid)\n",
    "print(\"Gradient Boosting Accuracy:\", gb_accuracy)\n",
    "print(\"Gradient Boosting Classification Report:\\n\", gb_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4aedfa3",
   "metadata": {},
   "source": [
    "Support Vector Machine Model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb794e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': [1, 0.1, 0.01, 0.001],\n",
    "    'kernel': ['rbf', 'linear']\n",
    "}\n",
    "svm_model = SVC()\n",
    "svm_best_model, svm_accuracy, svm_report = train_and_evaluate_model(svm_model, svm_param_grid)\n",
    "print(\"SVM Accuracy:\", svm_accuracy)\n",
    "print(\"SVM Classification Report:\\n\", svm_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86a77d4",
   "metadata": {},
   "source": [
    "Gradient Boost Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7491ad4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.5],\n",
    "    'max_depth': [3, 5, 7]\n",
    "}\n",
    "gb_model = GradientBoostingClassifier()\n",
    "gb_best_model, gb_accuracy, gb_report = train_and_evaluate_model(gb_model, gb_param_grid)\n",
    "print(\"Gradient Boosting Accuracy:\", gb_accuracy)\n",
    "print(\"Gradient Boosting Classification Report:\\n\", gb_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4838709",
   "metadata": {},
   "source": [
    "## Save models for future use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44455683",
   "metadata": {},
   "source": [
    "Use library to save model for export/import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f3d699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best models\n",
    "joblib.dump(rf_best_model, 'rf_best_model.pkl')\n",
    "joblib.dump(svm_best_model, 'svm_best_model.pkl')\n",
    "joblib.dump(gb_best_model, 'gb_best_model.pkl')\n",
    "\n",
    "# Save the scalers and encoders\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "joblib.dump(encoder, 'encoder.pkl')\n",
    "\n",
    "# Save the scaled data\n",
    "joblib.dump(X_train_scaled, 'X_train_scaled.pkl')\n",
    "joblib.dump(X_test_scaled, 'X_test_scaled.pkl')\n",
    "joblib.dump(y_train_encoded, 'y_train_encoded.pkl')\n",
    "joblib.dump(y_test_encoded, 'y_test_encoded.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
